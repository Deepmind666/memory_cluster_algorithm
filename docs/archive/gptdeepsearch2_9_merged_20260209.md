面向 GPT-5.3-Codex 的多智能体语义记忆碎片聚类压缩专利与实现提示词方案
背景与目标
在单机多智能体（multi-agent）协同完成复杂任务时，中间推理、工具输出、局部草稿、验证结论等都会不断堆积为“长期上下文”。在“代理循环”里，随着对话与工具调用增多，提示词（prompt）随之变长，最终会受限于上下文窗口与成本，并迫使系统做“上下文管理”。
 多智能体系统若采用共享记忆池，会更容易出现版本不一致、覆盖写、过期信息与冲突事实等“连贯性”问题，因此需要明确的协调与整理机制。

你的目标并不是“做一个泛用记忆系统”，而是为**“方向三：多 Agent 协同下的语义记忆碎片聚类压缩算法（含记忆保留偏好）”**准备一套可由 gpt-5.3-codex 在 Agent 模式下自动落地的工作说明：既能产出可运行的最小原型与文档，又能产出符合中国发明专利撰写习惯的技术交底书材料（说明书、权利要求书草案、摘要、附图说明、实施例等）。同时，你特别强调降低与现有专利/公开方案的“撞车风险”，因此提示词必须内置“检索—对比—绕开—收敛”的闭环流程，而不是直接写一份看似新颖但实际上容易落入公知组合的方案。

在工具侧，
的 Codex 体系明确把“能读写代码、能运行命令、能在独立环境执行任务并提供可核验痕迹”作为产品定位；并且 Codex 可通过仓库内的 AGENTS.md 获得项目级约束（测试命令、目录约定、最佳实践），这正是“把长提示词固化为可重复工作流”的最稳妥载体之一。

现有方法版图与多智能体差距
围绕“长对话/代理记忆压缩”，工程上常见策略大体可落到三类：保留最近窗口、把旧内容做摘要、把信息结构化再检索；这些策略在单会话里较好用，但多智能体场景会叠加两类新问题：跨 Agent 的重复描述与跨 Agent 的局部总结不一致，导致共享记忆越滚越杂。

以 
 为例，其 ConversationSummaryBufferMemory 用“最近若干轮原文 + 其余内容滚动摘要”的方式，在 token 上限约束下自动 prune，这代表了单会话“提炼式压缩”的典型形态：它维护一个运行摘要，并在超过 token 限额时裁剪/归并历史。
 但这类机制默认面向“一个对话线程”，并不天然解决“多个代理同时写入同一知识池”的去重、冲突标记、溯源与偏好保留等问题。

在企业多智能体产品侧，
 描述的多 Agent 协作强调“共享上下文与记忆存储（Shared Context and Memory Store）”，用于把数据、中间输出与决策放在一个共同空间，以保持协作连续性。
 这说明“共享记忆库”本身并不是新概念；真正拉开差异的，通常是：如何避免共享记忆库变成不可控的“堆栈”，以及如何把信息组织成可检索、可压缩、可追责的结构。

在开源/研究型系统里，MemBrain 公开把记忆管理拆成多子代理：实体抽取、对话总结、记忆合并、冲突消解、分层压缩等，并强调将检索方式工具化、让编排在运行时自适应。
 这类系统证明了“用多个记忆子模块/子代理协同”的有效方向，但你的切口更聚焦：把共享记忆写入的碎片先做语义聚类，再在簇内压缩，并把“记忆保留偏好”作为压缩控制变量，以解决多代理碎片化与偏好差异问题。

碰撞风险与可绕开空间
“避免与现有专利碰撞”在实践上只能做成风险降低，无法做成“保证不撞车”。原因是：相关主题覆盖面很广，从对话聚类、可控摘要、分层记忆、跨代理共享向量记忆到访问控制都已有公开文本与专利布局。你需要把提示词设计成：先检索、再对比、再组合差异点、最后再落笔到权利要求与实施例。

以下是与你方案最接近、也最容易“撞概念”的公开专利点位（用于风险雷达，而非穷尽检索）：

语义聚类本身早已出现于“对语料/utterances 做语义聚类”的专利中：例如 US20110238408A1 明确描述把用户自然语言输入做深度语言分析，再将语义图/语义表示聚成主题簇，用于识别高频主题、改进对话代理等。
 这意味着：如果你的权利要求只写“对对话做语义聚类并摘要”，非常容易落入既有披露范围或被认定为显而易见的常规改进。可绕开空间通常来自：聚类对象不是单一用户 utterance，而是多代理产出的异构‘记忆碎片’（含工具输出/中间结论/评测日志），并且聚类后“压缩单元”要携带可追溯索引与冲突标记机制，用于后续检索与还原。

“可控摘要/偏好驱动摘要”同样已有较多专利披露。例如 US12008332B1 直接把“提交的用户偏好”用于指导摘要行为（长度、风格、词汇适配、用途等），并指出偏好可直接影响摘要行为。
 这对你提出的“记忆保留偏好”是明显的先例压力。可绕开的空间通常来自：把偏好上升为‘写入/合并/降级’的系统级策略向量，不仅控制摘要长度，还控制（a）簇内去重与冲突保留，（b）跨簇层次化压缩阈值，（c）按来源代理可信权重的保留，（d）可逆还原的索引保留强度。也就是说，偏好不是“摘要格式化”，而是“多代理共享记忆的一致性与容量治理参数”。

“多代理共享向量记忆、并允许其它代理访问”也已有披露。例如 US20240289863A1 讨论把用户记忆嵌入成索引向量，并允许获得权限的其它对话代理访问这些记忆向量，以增强跨会话体验。
 因而，如果你的权利要求核心是“把记忆向量化并共享给多个代理”，也很容易撞入既有技术。可绕开的空间来自：强调你的重点不是“共享访问”，而是共享写入场景下对‘碎片’进行语义聚类与簇内压缩，显著降低冗余与上下文膨胀，并提供冲突标记与可追溯索引，属于“共享记忆的整理与压缩治理”。

此外，分层记忆结构 + 专门代理执行压缩/迁移/检索等“记忆管理工作流”在专利文本中也能见到。例如 EP 4 657 312 A1 描述多层记忆（working/long-term/collective 或不同访问级别的层），并指出可由专门子代理执行记忆管理操作，如压缩工作记忆数据并存入其它层、或跨层搜索并提取匹配信息；也提到专门工作流/微提示词用于生成可执行计划。
 这意味着：如果你只写“增加一个 Memory-Manager Agent 做分层压缩”，可绕开空间有限。你真正需要的差异点通常是：“语义聚类 + 冲突保留 + 偏好向量驱动的压缩/降级策略 + 层次化可逆索引”作为一个特定算法闭环，并在实施例里用多代理写专利/写代码的场景展示“重复去除、冲突显式化、偏好保真”的技术效果路径。

中国发明专利审查与撰写锚点
从中国专利法层面，发明与实用新型授权条件包括新颖性、创造性、实用性；同时，对“智力活动的规则和方法”等不授予专利权。
 因此，算法/记忆压缩不能写成纯抽象规则，必须组织为“技术方案”：用技术手段解决技术问题并产生技术效果，且在创造性论证上要围绕“对技术问题的贡献点”来写。

对“包含算法特征或商业规则方法特征”的申请，CNIPA 口径强调：审查不应简单割裂技术特征与算法特征，而应将权利要求记载的内容作为整体，分析技术手段、解决的技术问题与获得的技术效果。
 在 CNIPA 与 JPO 的对比报告中也明确：若算法与技术特征功能上相互支持、存在交互关系，则算法对技术方案的贡献应当被纳入创造性判断；并举例说明“减少数据存储/传输、提升硬件处理速度”等属于可被考虑的改进方向。
 这对你特别关键：你应把“上下文爆炸/共享记忆冗余”表述为计算机系统内部资源问题（存储、传输、处理时延、检索开销），把聚类压缩表述为降低资源占用、提升硬件执行效率/系统吞吐的技术手段。

2025 年发布、2026-01-01 起施行的《专利审查指南》修改中，新增/强化了与人工智能相关申请的审查规则与示例，引入对专利法第五条第一款（不违反法律、社会公德、不妨害公共利益）的审查规则，并强调必要时需结合说明书内容审查；同时也再次强调创造性评价应针对权利要求限定的整体技术方案。
 这意味着：你的专利材料应避免触碰非法数据采集/隐私违规等高风险实施例；在写“记忆偏好”时，宜落在“用户指定保留类别/系统策略参数”层面，避免写成“基于敏感个人信息推断偏好”的黑箱画像。

在撰写规范上，CNIPA 相关材料亦强调计算机程序类申请的说明书应清楚描述技术方案与流程图，并按流程步骤解释，使本领域技术人员能够据此实现；若写成装置/系统权利要求，也应明确硬件/软件部件及连接关系。

另外，2025 年的修改决定中明确：发明人应是自然人，不得在请求书中填写人工智能名称。
 同时专利法强调申请与行使专利权应遵循诚实信用原则。
 因而，你即便用 Codex 辅助写作，也应在提交文本时以“人类发明人对实质性特点做出创造性贡献”为叙事主线，不把 AI 当作发明人或替代责任主体。

方案架构与算法细化
你的“语义记忆碎片聚类压缩（含记忆保留偏好）”要写得像一个可实现的计算机系统算法模块，而不是概念描述。建议把系统分成三层：采集层（碎片化事件写入）、整理层（向量化—聚类—压缩—冲突处理）、服务层（检索注入与可逆还原），并在每个层给出输入输出数据结构与关键阈值。这样既利于工程落地，也利于专利说明书把算法特征与技术手段绑定到“存储/检索/传输/计算”资源上。

语义聚类压缩模块建议明确以下“可写入权利要求的技术要点”（本节为你方案的工程化定义，不是对现有技术的描述）：

碎片数据模型：每条记忆碎片（Memory Fragment）是一个最小信息单元，至少包含 id、agent_id、timestamp、content、type（对话/工具输出/中间结论/评测结果）、tags（主题/重要性/是否可丢弃/是否敏感）、provenance（可追溯引用，如文件路径、命令日志片段、原始碎片列表）。其中 provenance 用于保证压缩可逆：即使上层只保留簇摘要，也能在需要时定位到原始证据并“再水化（rehydrate）”。这一点对应了代理系统强调“可核验证据/日志”的工程趋势。

向量表示与增量聚类：为每个碎片计算语义向量（embedding），维护“簇（Cluster）”的代表向量（如 centroid）与簇内统计量（簇大小、最近更新时间、来源代理分布、冲突计数）。采用增量写入：新碎片到来时先做候选簇召回（近邻搜索），再做阈值归属（如余弦相似度 + 标签兼容约束）；若无匹配则新建簇。该形式本质是在不保留全部原文到上下文的前提下，把共享记忆的“去重与归档”外置到可控的数据结构里，从而把 token 压力转化为本地算力+存储的可管理开销。

簇内压缩：簇内压缩应拆为两步以避免“摘要吞掉边界条件”。第一步做结构化融合（去重、合并同义表述、抽取共识点、保留关键参数/阈值/文件路径）。第二步再做生成式摘要，并把输出约束为“可用于下游代理直接执行/检索”的格式（例如：结论 + 证据引用 + 未决问题）。这一点与通用滚动摘要不同：滚动摘要更像线性压缩，而簇内压缩是“同类合并”。

冲突标记与分裂策略：当簇内出现互斥事实（例如 A 代理说参数=0.7，B 代理说=0.2），不要简单投票后覆盖。建议把冲突记录为结构化字段：conflicts: [{slot, option_a, option_b, evidences, last_seen}]；并提供两种处理：轻量模式仅保留冲突提示，严格模式把冲突拆成子簇并要求验证代理补齐证据。多代理共享记忆的核心风险是“读到不一致版本”，而显式冲突标记能把不一致从隐式错误变成显式待处理事项。

记忆保留偏好：把“偏好”定义为一个配置对象，而不是一句自然语言愿望。至少包含：

类别偏好：对 tags.category 的保留强度（强保留/弱保留/可丢弃）与目标细节粒度（摘要长度上限、是否保留步骤/参数/证据）。
来源偏好：对 agent_id 的信任权重（例如 Expert/Verifier 产出更难被压缩丢失）。
时效偏好：过期策略（多久未被引用则降级到更高层摘要或移入冷存储）。
这类“可参数化的重要性”在摘要专利与共享记忆专利中都出现过，但你要把它落到“簇级压缩/降级/可逆索引”全过程的控制变量上，而不是仅控制摘要格式。
层次化与索引：当簇数量增长，再做二级聚类（对簇摘要再聚类）生成“主题级章节摘要”，形成树状结构；每个节点都保留 backrefs 指向下层簇/碎片。层次化的意义是把检索与上下文注入从“全量扫描”变成“先粗后细”，并把“压缩比—信息保真”交给偏好参数与 token 预算控制。

评价与可写入专利的技术效果路径：你需要在说明书里把“效果”写成计算机系统可度量指标，例如：

存储：共享记忆条目数、存储字节数、向量索引大小；
检索：每次构建上下文前的检索耗时、召回条目数、注入 token 数；
执行：代理完成任务的总轮次、失败重试次数；
并把这些指标与“减少数据存储/传输、提高处理速度”等 CNIPA 可认可技术效果表达对齐。
若你希望把方案更贴近“多代理写专利/写代码”的场景，还可以把“记忆碎片类型”明确为：需求碎片、决策碎片、方法步骤碎片、证据碎片（网页/论文/专利）、错误日志碎片、测试结果碎片；并在偏好里默认“强保留：方法步骤+证据+决策理由；弱保留：日志与闲聊”。这样你的实施例会更像一个面向技术写作/软件开发的专用系统，而不是泛对话摘要。

GPT-5.3-Codex 专用长提示词
下面给出一份可直接复制进 Codex（Agent 模式）的超长主提示词。它把任务拆成三个并行产出流：专利检索与绕开、算法原型实现、专利材料生成；并且显式利用 gpt-5.3-codex 的特性（更强推理、更快、支持工作中 “mid-turn steering”）以及 Codex 的工程载体（AGENTS.md、Skills、沙箱与审批策略、可运行命令与测试）。

md
复制
# 你是 gpt-5.3-codex（Codex Agent 模式）——本仓库的“全流程工程+专利写作代理”

## 总目标（不可偏离）
在一个全新仓库中，完成“多 Agent 协同下的语义记忆碎片聚类压缩算法（含记忆保留偏好）”的：
1) 可运行最小原型（单机）+ 单元测试 + 示例数据 + 基准评测脚本
2) 可读的技术设计文档（面向工程实现）
3) 中国发明专利用的技术交底书素材包（说明书草案、权利要求书草案、摘要、附图说明、实施例）
4) 现有技术/专利“撞车风险降低”材料：检索清单、特征对比矩阵、绕开方案与差异化权利要求策略

## 关键硬约束
- 我是零代码基础用户：你必须把一切做成“自动生成文件 + 可复制命令 + 明确下一步”。
- 不要只给建议，必须在仓库里落文件、落代码、落脚本、落运行说明。
- 不得把“AI”写成发明人；产出材料必须默认“发明人为自然人”，并给出显式提醒（我提交时自己填）。 
- 任何“看起来像”现有专利常见披露点（语义聚类、可控摘要、共享向量记忆、分层记忆、记忆管理代理）都可能撞车：
  你必须先做检索与对比，再定稿权利要求与实施例，避免直接写成“公知拼装”。

## 你应优先利用的 Codex 能力
- 以 Agent 模式读写文件、运行命令、跑测试、生成可核验输出。
- 允许我在你工作中途插话进行 steering：收到我新的指令后，立刻调整当前计划并继续推进。
- 用 AGENTS.md 固化仓库规则；用 Skills 固化可重复工作流；用 plan 文档跟踪长任务。

## 安全与执行模式（建议默认）
- 默认在安全模式下工作：只在仓库目录内读写。
- 如需联网检索：先请求允许；若我允许，再进行“最小必要”的检索并把来源写入 docs/prior_art/。
- 不要使用危险的全盘权限模式；不要运行不可逆命令（rm -rf、重写历史、清空目录等）。

---

# 第一阶段：自举仓库结构（必须先做）
## 1.1 生成目录结构
在仓库根目录创建：
- AGENTS.md
- .codex/skills/memory-cluster-patent-kit/SKILL.md
- docs/
  - design/
  - prior_art/
  - patent_kit/
  - eval/
- src/memory_cluster/
- tests/
- data/examples/

## 1.2 写 AGENTS.md（仓库契约）
AGENTS.md 必须包含：
- 本仓库目标与交付清单
- 默认运行命令（pytest、lint 若有）
- 代码风格（Python 3.10+；类型注解；不引入重依赖；可选依赖必须在 requirements.txt）
- 变更策略：小步提交（如果你能提交）、每阶段写 “DONE” 清单
- 文档策略：所有核心结论必须落到 docs/ 中对应文件

## 1.3 写 Skill：memory-cluster-patent-kit
该 Skill 触发条件：
- 当任务包含关键词：记忆、memory、聚类、clustering、压缩、compression、偏好、preference、专利、patent、权利要求、实施例
该 Skill 行为：
- 自动创建/更新以下文件：docs/design/algorithm_spec.md、docs/prior_art/search_log.md、docs/prior_art/feature_matrix.md、docs/patent_kit/*.md
- 强制执行“先检索对比 → 再定稿”的流程门禁
- 输出必须“可审计”：每条现有技术条目要有来源、摘要、可能撞车点、绕开建议

---

# 第二阶段：现有技术/专利检索与绕开（门禁：未完成不得写权利要求定稿）
## 2.1 检索范围
至少覆盖：
A. 专利（优先）：
- 语义聚类（semantic clustering）与对话/语料聚类
- 可控摘要（controllable summarization）与用户偏好驱动摘要
- 多代理共享记忆（shared memory / collective memory / cross-agent memory vectors）
- 分层记忆（layered memory structures）与记忆压缩/迁移工作流
B. 论文/开源：
- 多代理记忆管理、长期记忆、冲突消解、分层压缩
- 长期记忆基准（如 LongMemEval 等）

## 2.2 产物文件（必须写入）
- docs/prior_art/search_log.md
  - 逐条记录：检索关键词、时间、结果链接/编号、简述
- docs/prior_art/feature_matrix.md
  - 用“特征点清单”的方式对比至少 15 条现有技术（专利/论文/系统混合）
  - 每条现有技术列出：已披露特征、与你方案的重合区、可能的绕开角度
- docs/prior_art/design_around.md
  - 给出至少 3 套“绕开组合方案”（不同权利要求主线），并说明取舍

## 2.3 绕开策略（必须执行）
在写我的方案时，你必须把创新点落在“组合差异”上，例如：
- 聚类对象：多 Agent 异构记忆碎片（含工具输出/中间结论/评测日志），而非单一用户 utterance
- 压缩单元：簇内融合 + 冲突显式标记 + 可逆 backref 索引
- 偏好：不是摘要格式偏好，而是“写入/合并/降级/再水化”的系统级策略向量
- 一致性：跨 Agent 版本/冲突治理机制（保留少数派观点的证据指针）
- 可度量技术效果：减少存储、减少传输、提高检索吞吐、降低上下文注入 token 预算

---

# 第三阶段：算法原型实现（单机可跑）
## 3.1 语言与依赖约束
- Python 3.10+
- 依赖尽量少：建议 numpy、scikit-learn（可选）、pydantic（可选）
- 向量化：
  - 默认提供一个“可替换接口”，允许：
    1) 本地简化 embedding（TF-IDF 或 sentence-transformers 若安装）
    2) 未来替换为在线 embedding（但本仓库默认不依赖在线）
- 聚类：
  - 默认实现“增量阈值聚类”（online centroid clustering）
  - 可选实现：MiniBatchKMeans 或 BIRCH（作为对照实验）

## 3.2 模块划分（必须照此落文件）
src/memory_cluster/
- models.py：Fragment、Cluster、PreferenceConfig、ConflictRecord 等数据结构
- embed.py：EmbeddingProvider 抽象 + 至少一个本地实现
- cluster.py：增量聚类器（assign/update/split/merge）
- compress.py：簇内融合、摘要接口（先结构化融合，后摘要生成的“占位实现”）
- preference.py：偏好解释器（类别/来源/时效）→ 压缩与保留策略
- store.py：本地存储（JSONL 或 SQLite 二选一），支持 backref 与版本
- retrieve.py：检索接口（按 query 找簇→按需展开碎片）
- eval.py：指标计算（压缩比、重复率下降、冲突率、召回/命中等）
- cli.py：命令行入口（demo：导入碎片→聚类→压缩→查询→导出）

## 3.3 示例场景（必须提供）
data/examples/ 下提供一个“多 Agent 写专利/写代码”的模拟日志：
- planner_agent、writer_agent、verifier_agent 三个来源
- 至少包含：重复需求、不同表述、一次参数冲突、若干日志噪声
并在 docs/eval/demo_walkthrough.md 里给出“跑通命令 + 预期输出”。

## 3.4 测试（必须跑过）
tests/ 下至少：
- test_clustering_basic.py（相似碎片能聚到一起）
- test_conflict_marking.py（冲突能被检测并记录）
- test_preference_policy.py（偏好能改变保留力度）
- test_store_roundtrip.py（backref 可追溯、序列化不丢字段）

---

# 第四阶段：中国发明专利材料生成（基于第二阶段绕开策略，才允许定稿）
## 4.1 必须生成的文件（中文）
docs/patent_kit/
- 00_技术交底书_总览.md（交付清单、术语表、符号说明）
- 01_背景技术.md
- 02_发明内容_技术问题与效果.md（把“上下文爆炸”写成计算机资源问题）
- 03_技术方案_系统与流程.md（系统结构 + 流程步骤 S1..Sn + 数据结构）
- 04_附图说明.md（至少 4 张图：系统框图、流程图、数据结构图、偏好策略图）
- 05_具体实施方式.md（多实施例：偏好不同、冲突处理不同、层次压缩不同）
- 06_权利要求书_草案.md（至少 1 组独立权利要求：方法 + 系统/装置 + 存储介质；再配 10+ 从属）
- 07_摘要.md（≤300 字风格，强调技术效果）
- 08_对比文件与绕开说明.md（把 feature_matrix 的结论转写成“差异点叙事”）

## 4.2 权利要求写作门槛（必须遵守）
- 独立权利要求必须体现“技术手段—技术问题—技术效果”的闭环，并且可落实到计算机系统内部性能指标：
  例：减少存储、减少传输、提高检索速度/吞吐、降低上下文注入 token 预算
- 必须包含“碎片元数据 + 语义向量 + 增量聚类 + 簇内压缩 + 冲突标记 + 偏好策略 + backref 索引”中至少 4 个耦合点
- 不许只写“对话摘要/文本总结”的抽象规则
- 任何敏感/违法采集内容一律不写实施例

---

# 第五阶段：最后验收（Definition of Done）
你必须在仓库根目录生成 docs/FINAL_REPORT.md，包含：
- 我该如何一键运行 demo（复制命令）
- demo 输出截图/节选（文本即可）
- 压缩效果数字（至少 3 个指标）
- 专利材料清单（含各文件路径）
- 撞车风险雷达：Top 5 风险点 + 对应绕开点（来自 feature_matrix）

---

# 工作方式要求（执行纪律）
- 先并行收集信息，再统一收敛：能并行就并行（读文件/检索/生成草稿）。
- 每完成一个阶段，在 docs/FINAL_REPORT.md 更新进度。
- 如果我中途发来 steering 指令：立刻停下当前子任务，更新计划并继续。
- 任何不确定的地方，不要停在提问：给出“合理默认 + 可选分支”，并继续推进。
上述提示词适配 gpt-5.3-codex 的关键点在于：

明确选择 gpt-5.3-codex 作为 Codex 推荐模型，并利用其更快与更可协作的特性（更频繁进度更新、支持工作中 steering）。
以 AGENTS.md 固化项目级规则，并可叠加项目覆盖层，实现“每个任务开局一致”。
以 Skills 固化“先检索对比再定稿”的门禁流程，并用 SKILL.md 的 name/description 提升触发可靠性。
默认使用安全沙箱与审批策略，避免在零代码用户环境中出现不可逆破坏，同时给出可选的授权升级路径。
这份主提示词的设计目的，是让 Codex 在单机上可执行地完成“技术开发 + 专利材料”双交付，并将“降低撞车风险”变成硬门禁流程，而不是一句口号。# GPT-5.3 Codex Agent 主任务说明书（专利交底 + 工程执行）

最后更新：2026-02-09  
适用环境：Windows（优先）/ Linux（兼容）

## 1. 任务定位
你是 Codex Agent，目标不是“写一篇空泛说明”，而是输出一套**可执行、可审计、可交接**的方案，用于支撑以下主题：

> 基于 GPU/CPU 运行态反馈的代码生成优化闭环（生成 -> 执行 -> 监测 -> 分析 -> 优化 -> 再生成）

你必须同时完成：
- 技术交底书草案（中文、结构化、可用于后续专利文本整理）。
- 自动化执行说明（命令、脚本、日志产物、错误处理）。
- 风险评估（尤其是现有论文/专利重叠风险）。

## 2. 非功能强制要求
- 全流程记录：每个关键步骤必须写入 `WORK_PROGRESS.md`，包含时间戳、动作、文件清单、评审清单。
- 结论可追踪：每个“关键判断”必须附来源链接。
- 禁止伪造实验：示例数据必须可复现实跑，禁止编造性能数字。
- 先正确再优化：先保证可运行，再进入性能迭代。
- 输出分层：给零代码用户可直接复制粘贴的命令与模板。

## 3. 法律与合规边界（必须遵守）
- 不宣称“绝对新颖性”或“必然授权”。
- 使用“初步检索显示”“存在重叠风险”“需代理人复核”等谨慎措辞。
- 对已有公开技术，必须做对比并明确差异化定位。
- 该文档仅用于技术与流程准备，不是法律意见。

## 4. 截止 2026-02-09 的先行技术基线（初步）

### 4.1 论文与技术工作
1. PerfCodeGen（arXiv:2412.03578）
- 关键词：execution feedback、代码性能优化。
- 对本方案的启发：执行反馈有效，但多以运行结果驱动，硬件多指标联动深度仍可扩展。
- 来源：https://arxiv.org/abs/2412.03578

2. POLO（IJCAI 2025）
- 关键词：项目级代码性能优化、多代理。
- 对本方案的启发：项目级优化可行，但实现复杂，单机闭环可继续精简落地。
- 来源：https://www.ijcai.org/proceedings/2025/814

3. ECO（OpenReview）
- 关键词：performance-aware prompting。
- 对本方案的启发：提示词层可驱动性能改善，但应与本地硬件观测闭环结合。
- 来源：https://openreview.net/forum?id=KhwOuB0fs9

4. EffiLearner（OpenReview）
- 关键词：强化学习 + 测试时优化。
- 对本方案的启发：反馈驱动优化趋势明确，需强调你方案中的“硬件信号粒度”与“单机可执行性”。
- 来源：https://openreview.net/forum?id=R5L1TD1Z58

5. SWE-Perf（OpenReview）
- 关键词：性能缺陷修复基准。
- 对本方案的启发：可作为后续评估基准来源，避免只做主观性能叙述。
- 来源：https://openreview.net/forum?id=KxFaKvtBiG

### 4.2 专利风险基线（初步）
1. US11941378B1（2024-03-26 授权）
- 标题涉及“利用生产洞察改进生成式 AI 模型”。
- 风险点：运行数据反哺生成逻辑的框架思想存在重叠。
- 来源：https://patents.google.com/patent/US11941378B1/en

2. US20250130778A1（2025-04-17 公布）
- 标题涉及“基于性能分析改进代码生成”。
- 风险点：性能分析驱动代码优化，与本任务主题接近。
- 来源：https://patents.google.com/patent/US20250130778A1/en

3. CN119917107A（2025-05-06 公布）
- 标题涉及“大模型自动化代码审查与修复”。
- 风险点：虽然聚焦审查修复，但同属 AI 代码闭环流程，应评估权利要求边界。
- 来源：https://patents.google.com/patent/CN119917107A/en

4. US11941373B2（2024-03-26 授权）
- 标题涉及“代码质量评估的强化学习优化”。
- 风险点：反馈驱动生成策略与 RL 调优思路有相邻区域。
- 来源：https://patents.google.com/patent/US11941373B2

5. US20250165890A1（2025-05-22 公布）
- 标题涉及“机器学习辅助开发环境性能优化”。
- 风险点：IDE/开发流程级性能建议与本任务存在应用场景邻近。
- 来源：https://patents.google.com/patent/US20250165890A1/en

## 5. 差异化定位建议（写作策略）
为降低碰撞风险，交底书应强调以下组合，而非单点口号：
- 强调“单机高性能设备场景（非集群）”。
- 强调“多维硬件信号协同”（CPU 占用、GPU 显存、功耗/温度、I/O 等）。
- 强调“闭环中的自动策略生成机制”（反馈解释器 -> 策略选择器 -> 代码再生成）。
- 强调“可审计证据链”（日志、配置、版本、基线对照）。
- 强调“先正确性门禁，再性能门禁”的双门控流程。

## 6. Codex Agent 执行流程（硬约束）
1. 初始化
- 读取任务文档、确认目录结构、写入进展日志首条记录。

2. 环境探测
- 检查 Python、GPU 监测工具、系统权限。
- 产出环境快照 `env_snapshot.json`。

3. 基线代码生成
- 先产出功能正确版本。
- 运行单元测试或最小可执行验证。

4. 监测与采样
- 采集 CPU/GPU/内存/耗时指标。
- 产出 `perf_raw.json` 与终端摘要。

5. 反馈解释
- 依据阈值识别瓶颈类型。
- 产出 `feedback_report.md`。

6. 优化再生成
- 仅改动瓶颈相关代码，保留可读性。
- 每轮必须记录“改动点-依据-结果”。

7. 收敛判定
- 达到目标阈值或 2 轮连续提升 < 5% 即停止。
- 产出最终版本与对照表。

8. 文档汇总
- 生成技术交底稿、流程图、参考文献与风险说明。

## 7. 输出文件规范（建议）
- `outputs/env_snapshot.json`
- `outputs/perf_raw.json`
- `outputs/perf_summary.md`
- `outputs/feedback_report.md`
- `outputs/optimization_rounds.json`
- `outputs/final_disclosure.md`
- `outputs/figures/flowchart.svg`

## 8. 质量门禁（提交前必须逐项通过）
- 功能正确性：优化前后输出一致或误差可解释。
- 性能证据：有原始数据、有统计方法、有可复现命令。
- 可读性：关键逻辑有注释，文档结构分明。
- 追踪性：每条关键结论可追溯到日志或来源。
- 风险控制：包含专利重叠风险段落与非法律声明。

## 9. 可直接复用的主提示词模板
将下方模板交给 Codex Agent：

```text
你是 Codex Agent。请在当前仓库执行“运行态反馈驱动代码优化闭环”任务，严格遵守：
1) 先功能正确，后性能优化；
2) 每个关键步骤写入 WORK_PROGRESS.md（时间戳+动作+文件+评审清单）；
3) 产出 outputs/ 下的结构化证据文件；
4) 不伪造实验数据，必须实测；
5) 在最终文档中加入先行技术对比与碰撞风险说明，禁止宣称绝对新颖性。

任务目标：
- 生成并优化一份可运行代码；
- 采集并分析 CPU/GPU 运行态数据；
- 完成“技术交底书草案 + 流程图 + 参考文献列表”；
- 给出后续需专利代理人复核的风险清单。

输出要求：
- 中文为主，结构化 Markdown；
- 所有关键结论带来源链接；
- 给出复现实验命令；
- 最终提供变更文件清单和下一步建议。
```

## 10. 最终交付检查清单
- [ ] 文档结构完整（背景、问题、方案、实施例、对比、风险、结论）。
- [ ] 有可运行示例与真实性能日志。
- [ ] 有流程图并在文档引用。
- [ ] 有先行技术引用与日期说明。
- [ ] 有“非法律意见”声明。
- [ ] `WORK_PROGRESS.md` 记录完整且时间连续。

---

## 附录 A：参考链接
- PerfCodeGen: https://arxiv.org/abs/2412.03578
- POLO (IJCAI 2025): https://www.ijcai.org/proceedings/2025/814
- ECO (OpenReview): https://openreview.net/forum?id=KhwOuB0fs9
- EffiLearner (OpenReview): https://openreview.net/forum?id=R5L1TD1Z58
- SWE-Perf (OpenReview): https://openreview.net/forum?id=KxFaKvtBiG
- US11941378B1: https://patents.google.com/patent/US11941378B1/en
- US20250130778A1: https://patents.google.com/patent/US20250130778A1/en
- CN119917107A: https://patents.google.com/patent/CN119917107A/en
- US11941373B2: https://patents.google.com/patent/US11941373B2
- US20250165890A1: https://patents.google.com/patent/US20250165890A1/en

> 注：以上为截至 2026-02-09 的初步检索基线，不替代专利法律检索与侵权分析。

初步技术方案：
# ✅ 交给 GPT-5.3-Codex（Agent 模式）的总提示词：单机多 Agent「语义记忆碎片聚类压缩（含保留偏好）」技术开发

> 你现在是 **GPT-5.3-Codex 工程智能体（Agent 模式）**。你的任务不是写论文/专利，而是**先把系统原型做出来**：可运行、可复现、可扩展、可解释，并为后续“发明专利材料撰写”提供工程证据与结构化描述（流程、模块、参数、指标、对比基线、Demo 结果）。

---

## 0. 最高优先级目标（必须达成）
1. **产出一个可运行的本地项目仓库**（Python 优先，跨平台：Windows / Linux）。
2. 支持 **多 Agent 碎片输入 → 语义向量化 → 增量聚类 → 簇内去冗余融合 → 摘要压缩 → 冲突标记 → 偏好驱动保留策略 → 分层压缩索引** 的完整闭环。
3. 提供 **一键 Demo**：模拟 3~5 个 Agent 输出碎片，展示压缩前后 token/字数变化、检索效果、冲突标记、偏好调参效果。
4. 提供 **最小可用 API**：`ingest(fragment)`, `retrieve(query, preference_profile)`, `export_memory()`, `explain(cluster_id)`.
5. 输出 **README + 架构图 + 参数说明 + 评测脚本**，让零代码用户只需复制命令即可跑通。

---

## 1. 约束与工程原则（强约束）
- **单机运行**：不要依赖分布式数据库、消息队列等重型外部组件。
- **可选依赖策略**：
  - 默认：`sentence-transformers` 做 embedding；`faiss-cpu` 做向量近邻（可选）。
  - 兜底：若 embedding 模型不可用，则用 `TfidfVectorizer` + 余弦相似作为退化方案（保证可跑）。
  - 摘要压缩：默认先做**可解释的抽取式压缩**（句子级去重 + 关键句挑选），再提供可选 LLM 摘要接口（默认关闭，用户可后续接入）。
- **强调可解释性**：每个“压缩单元”必须能追溯原始碎片 ID（可回放）。
- **避免“拍脑袋魔法”**：所有阈值、偏好、权重都必须可配置，并在 README 解释其作用。
- **后续专利友好**：在代码与文档中保留“流程编号（S1~S7）”、参数、数据结构定义、对比基线接口（但不要写成专利口吻）。

---

## 2. 系统总体架构（你必须实现）
### 2.1 核心角色
- **Memory-Manager（记忆管理器）**：唯一核心模块，负责 ingest→聚类→压缩→索引→检索。
- **Fragment（记忆碎片）**：多 Agent 产生的最小信息单元（对话轮次/工具输出/中间结论）。
- **Cluster（语义簇）**：语义相近碎片集合；簇内维护 centroid、代表摘要、冲突集合、重要度统计。
- **Preference Profile（记忆保留偏好）**：可配置“保留策略”，决定哪些类信息保留细节/哪些强压缩/哪些可丢弃。

### 2.2 数据流（必须按此实现）
S1. 收集碎片（带元数据）  
S2. 向量化（embedding / TFIDF 退化）  
S3. 增量聚类（online clustering，基于相似阈值 + centroid 更新）  
S4. 簇内压缩（去冗余 → 融合 → 摘要）  
S5. 冲突检测与标记（保留矛盾点，不强行合并）  
S6. 偏好驱动保留（按标签/来源/时间/重要度调整摘要长度与保留项）  
S7. 分层压缩与索引（簇摘要可再聚类生成上层摘要树；保留引用链）

---

## 3. 模块拆分（你要按文件实现，且写单元测试）
建议模块（可微调，但职责必须完整）：
- `fragment.py`：Fragment 数据类、规范化、标签体系、token/字数估算
- `embedding.py`：EmbeddingProvider（ST / TFIDF fallback），缓存与批处理
- `cluster.py`：OnlineClusterer（阈值归簇、centroid 更新、簇合并/拆分）
- `compression.py`：簇内去冗余、融合、抽取式摘要；可选 LLM 摘要接口（默认关闭）
- `conflict.py`：冲突检测（MVP 先做规则+数值冲突；可扩展 NLI/LLM）
- `preference.py`：PreferenceProfile、打分函数、保留策略执行器
- `memory_store.py`：持久化（SQLite 或 JSONL + 索引），版本与可追溯引用链
- `retrieval.py`：查询检索（向量检索 + 关键词检索 + 偏好重排）
- `demo.py`：多 Agent 模拟器 + 可视化输出（终端表格即可）
- `cli.py`：命令行：`demo / ingest / retrieve / export / explain`
- `tests/`：pytest 覆盖核心逻辑
- `configs/`：默认配置 + 示例偏好配置

---

## 4. 关键数据结构（你必须严格定义）
### 4.1 Fragment（最小单元）
字段建议：
- `fragment_id: str`（UUID）
- `agent_id: str`（来源 Agent）
- `timestamp: int`
- `content: str`
- `tags: list[str]`（如：method_steps, user_requirements, error_log, decision_rationale, chit_chat）
- `task_id: str | None`
- `importance_hint: float | None`（来源端可给提示）
- `refs: list[str]`（引用的其它 fragment/cluster）

### 4.2 Cluster（语义簇）
- `cluster_id: str`
- `centroid: np.ndarray`
- `fragment_ids: list[str]`
- `summary: str`（簇代表记忆）
- `conflicts: list[ConflictItem]`
- `topic_tags: dict[tag, score]`
- `stats: {created_at, updated_at, access_count, compression_ratio, ...}`

### 4.3 PreferenceProfile（偏好配置）
必须支持至少这四类偏好：
1) **内容类型偏好**：哪些 tag 必须保留细节（白名单）、哪些强压缩（黑名单/灰名单）
2) **来源偏好**：Agent 信任权重（如 expert_agent > exec_agent）
3) **时间偏好**：近期优先 or 历史决策优先（可用衰减函数）
4) **预算偏好**：给定 token/字数预算，决定压缩力度（summary 长度/保留原句数量）

---

## 5. 核心算法路线（必须先做 MVP，再做增强）
### 5.1 Online 增量聚类（MVP 必做）
目标：新碎片到来时 O(logN) 或近似 O(1) 找最近簇并决定归属。
- 步骤：
  1) embed(fragment)
  2) 在簇 centroid 上做近邻搜索（无 faiss 则全量余弦，MVP 可接受）
  3) 若 max_sim >= `assign_threshold` → 加入该簇并更新 centroid（滑动平均）
  4) 否则新建簇
  5) 周期性簇合并：若 centroid 相似度 >= `merge_threshold` 合并
- 关键参数必须可配置：`assign_threshold`, `merge_threshold`, `max_cluster_size`

### 5.2 簇内压缩（MVP：可解释抽取式）
必须包含三步：
1) **去冗余**：句子级相似度去重（embedding 或 TFIDF）
2) **融合**：同义句合并（MVP 用规则：保留信息量最大的一句；增强版可 LLM）
3) **摘要**：按偏好输出不同长度（短/中/长三档）

### 5.3 冲突检测（MVP 可规则化）
MVP 先做：
- 数值冲突：同字段出现不同数值（正则抽取 + 比较）
- 否定冲突：出现“不是/不需要/禁止/无法” vs 肯定表述（简单规则）
输出：
- `conflict_type`, `evidence_fragments`, `note`

### 5.4 偏好驱动保留（必须做出“可见的效果”）
实现一个 `importance_score(fragment, profile)`：
- `score = w_tag + w_agent + w_recency + w_access + w_hint`
压缩阶段按 score 排序保留 top-K 关键句，其余汇总。
要求 Demo 能展示：换 profile 后 summary 明显变化。

### 5.5 分层压缩（增强版，做得到就做）
当簇摘要数量过多：
- 对簇摘要再聚类，生成 L2 summary（树形结构）
- 每个 L2 节点保留子簇引用列表（可展开）

---

## 6. 工程实现路线（你必须按阶段交付并自测）
### Phase 0：仓库骨架（立刻做）
- 初始化 `pyproject.toml`（建议用 hatch/poetry 任一）
- 加入 `pytest`, `ruff`（可选 `mypy`）
- 提供 `Makefile` 或 `scripts/` 一键命令（Windows 也能跑：提供 python 命令等价）

### Phase 1：数据结构 + 持久化
- 实现 Fragment/Cluster/Profile 数据类
- MemoryStore：支持 save/load（JSONL 或 SQLite）
- 单元测试：序列化/反序列化一致性

### Phase 2：向量化与缓存
- EmbeddingProvider：ST + fallback TFIDF
- 批处理 embedding（减少重复计算）
- 测试：同文本向量稳定；fallback 可用

### Phase 3：OnlineClusterer
- 阈值归簇 + centroid 更新 + 合并策略
- 测试：相似碎片进入同簇；不相似进入新簇

### Phase 4：Compression + Conflict
- 去冗余 + 抽取式摘要
- 冲突规则检测
- 测试：重复句减少；冲突样例能标记

### Phase 5：PreferenceEngine + Retrieval
- 偏好 profile 生效：同一簇按 profile 输出不同摘要
- Retrieval：query → 返回 cluster summaries（向量检索 + 关键词）
- 测试：profile 改变输出；检索能命中正确簇

### Phase 6：Demo & README
- `python -m memcluster.demo` 一键运行
- 输出对比：
  - 原始碎片总字数 vs 压缩后字数
  - 每簇 summary
  - 冲突清单
  - 不同偏好 profile 的 summary 对比
- README 必须含：
  - 架构图（Mermaid）
  - 配置说明
  - 快速开始（复制命令即可）

---

## 7. 评测指标（必须实现脚本，哪怕是 toy）
至少输出这些：
- **Compression Ratio**：压缩后字数 / 原始字数
- **Redundancy Removal**：去重前后重复率变化（可用相似句计数）
- **Retention Proxy**：关键标签句子保留率（tag 白名单）
- **Conflict Coverage**：冲突标记数量与证据
- **Latency**：ingest 平均耗时（粗略即可）

提供 `evaluate.py`：跑 demo 数据集，打印一份结果报告。

---

## 8. Demo 数据集（你必须内置）
在 `demo.py` 内置一个小型多 Agent 场景：
- agents：`planner_agent`, `executor_agent`, `verifier_agent`, `expert_agent`
- 生成至少 40 条碎片，其中包含：
  - 5 组明显重复（不同表述）
  - 3 组冲突（数值/否定）
  - 多种 tag（method_steps / decision_rationale / error_log / chit_chat）
- 提供 2 份偏好 profile：
  - `profile_patent_like.yaml`：强保留 method_steps + decision_rationale
  - `profile_debug_like.yaml`：强保留 error_log，压缩背景闲聊

---

## 9. 输出物（你最终必须交付的文件清单）
仓库根目录至少包含：
- `README.md`
- `pyproject.toml`
- `memcluster/`（源码包）
- `configs/`（偏好与阈值配置）
- `tests/`
- `scripts/` 或 `Makefile`
- `docs/architecture.md`（含 Mermaid 图 + S1~S7 流程）

---

## 10. 工作方式要求（Agent 模式执行规范）
你必须循环执行：
1) 先列出计划（文件树 + 里程碑）
2) 实现最小可用版本（MVP）
3) 跑测试并修复
4) 再做增强（可选）
5) 最后输出一份“开发完成报告”（包括如何运行、指标结果、已知限制、下一步）

不要向用户提问（用户零代码），你必须自己做默认决策；若必须二选一，则选择**更稳、更容易跑通**的方案。

---

## 11. 你必须避免的坑（红线）
- 不要只写概念不落地：必须有代码可运行。
- 不要依赖外部在线服务才能跑通 Demo（LLM 摘要必须可选关闭）。
- 不要把所有逻辑塞在一个文件：必须模块化 + 测试。
- 不要把“冲突”直接消解掉：要**保留冲突证据链**。
- 不要做不可解释的压缩：必须能回溯原始碎片。

---

## 12. 完成后的“下一步”（仅在报告末尾简述）
在原型跑通后，再进入专利写作阶段：把你实现的 S1~S7、数据结构、偏好参数、对比基线、实验指标，转写成说明书与权利要求的工程依据。

---

# ✅ 现在开始执行：请先输出【仓库文件树规划】+【Phase 0~6 里程碑】+【你将采用的默认依赖与fallback】，
然后直接创建代码与文档，跑通 demo 与 tests，并给出最终报告。
